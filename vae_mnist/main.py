import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersimport numpy as npfrom network.py import *# Importind MNIST data set(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()#Concetenation of train and test dataX_train = np.concatenate((X_train,X_test), axis=0)#Normalizing imagesX_train = X_train / 255.0# Preparing dataset for trainingbatch_size = 128train_dataset = tf.data.Dataset.from_tensor_slices((X_train)).batch(batch_size)#Sampling Class for output of the decoderclass Sampling(layers.Layer):    def call(self, inputs):        mean, var = inputs        batch = tf.shape(mean)[0]        dim = tf.shape(mean)[1]        eps = tf.keras.backend.random_normal(shape=(batch, dim))        return mean + tf.exp(0.5 * var) * eps    # Choosing optimizeroptimizer = tf.optimizers.Adam(0.001)# Training function @tf.functiondef train_step(inputs, model):    with tf.GradientTape() as tape:        encoder = model.encoder        decoder = model.decoder        mean, var, z = encoder(inputs)        generated_image = decoder(z)        generated_image = tf.reshape(generated_image, (-1, 28,28,1))        ce_loss = ce_loss_fn(inputs, generated_image)        kl_loss = kl_loss_fn(var, mean)        total_loss = ce_loss + kl_loss    grads = tape.gradient(total_loss, model.trainable_weights)    optimizer.apply_gradients(zip(grads, model.trainable_weights))    return total_loss, ce_loss, kl_loss# Tracker lists of loss functions total_loss_list = []ce_loss_list = []kl_loss_list = []epochs = 150for epoch in range(epochs):  batch_total_loss = []  batch_ce_loss = []  batch_kl_loss = []  for step, (x_batch_train) in enumerate(train_dataset):    total_loss, ce_loss, kl_loss = train_step(x_batch_train, vae)    batch_total_loss.append(total_loss.numpy())    batch_ce_loss.append(ce_loss.numpy())    batch_kl_loss.append(kl_loss.numpy())  epoch_total_loss = round(sum(batch_total_loss) / len(batch_total_loss), 4)  epoch_ce_loss = round(sum(batch_ce_loss) / len(batch_ce_loss), 4)  epoch_kl_loss = round(sum(batch_kl_loss) / len(batch_kl_loss), 4)   total_loss_list.append(epoch_total_loss)  ce_loss_list.append(epoch_ce_loss)  kl_loss_list.append(epoch_kl_loss)  print((epoch+1),". Total Loss:", epoch_total_loss, " CE Loss:", epoch_ce_loss, " KL Loss:", epoch_kl_loss)  print("-------------------------------------------------------------------")                                        